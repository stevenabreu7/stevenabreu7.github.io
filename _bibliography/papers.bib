---
---

@string{aps = {American Physical Society,}}

@misc{abreu2024qs5,
      title={Q-S5: Towards Quantized State Space Models}, 
      author={Steven Abreu and Jens E. Pedersen and Kade M. Heckel and Alessandro Pierro},
      year={2024},
      eprint={2406.09477},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      arxiv={https://arxiv.org/abs/2406.09477}, 
      selected      = {true},
      bibtex_show   = {true},
      note = {Presented at ICML workshop NGSM},
      preview={qs5.png},
      code={https://github.com/stevenabreu7/Q-S5},
      journal = {ICML 2024 (NGSM workshop},
}

@misc{pierro2024mambaptqoutlierchannelsrecurrent,
      title={Mamba-PTQ: Outlier Channels in Recurrent Large Language Models}, 
      author={Alessandro Pierro and Steven Abreu},
      year={2024},
      eprint={2407.12397},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      arxiv={https://arxiv.org/abs/2407.12397},
      note={Presented at ICML workshop ES-FOMO-II},
      selected      = {true},
      bibtex_show   = {true},
      preview={mambaptq.png}, 
      journal = {ICML 2024 (ES-FOMO-II workshop)},
}

@article{pedersen2023neuromorphicintermediaterepresentationunified,
      title={Neuromorphic Intermediate Representation: A Unified Instruction Set for Interoperable Brain-Inspired Computing}, 
      author={Jens E. Pedersen and Steven Abreu and Matthias Jobst and Gregor Lenz and Vittorio Fra and Felix C. Bauer and Dylan R. Muir and Peng Zhou and Bernhard Vogginger and Kade Heckel and Gianvito Urgese and Sadasivan Shankar and Terrence C. Stewart and Jason K. Eshraghian and Sadique Sheik},
      year={2024},
      journal={Nature Communications},
      arxiv={https://arxiv.org/abs/2311.14641}, 
      note={in press},
      selected = {true},
      bibtex_show = {true},
      preview = {nir.png},
      code={https://github.com/neuromorphs/nir},
}

@article{abreu2024parseego4dpersonalactionrecommendation,
      title         ={PARSE-Ego4D: Personal Action Recommendation Suggestions for Egocentric Videos}, 
      author        ={Steven Abreu and Tiffany D. Do and Karan Ahuja and Eric J. Gonzalez and Lee Payne and Daniel McDuff and Mar Gonzalez-Franco},
      year          ={2024},
      eprint        ={2407.09503},
      archivePrefix ={arXiv},
      primaryClass  ={cs.CV},
      arxiv           ={https://arxiv.org/abs/2407.09503}, 
      selected      = {true},
      bibtex_show   = {true},
      preview       = {parse-ego4d.png},
      website = {https://parse-ego4d.github.io/},
      code = {https://github.com/parse-ego4d/parse-ego4d.github.io},
      journal = {under review},
}

@article{abreu2024photonics,
title = {A photonics perspective on computing with physical substrates},
journal = {Reviews in Physics},
volume = {12},
pages = {100093},
year = {2024},
issn = {2405-4283},
doi = {https://doi.org/10.1016/j.revip.2024.100093},
url = {https://www.sciencedirect.com/science/article/pii/S2405428324000030},
author = {S. Abreu and I. Boikov and M. Goldmann and T. Jonuzi and A. Lupo and S. Masaad and L. Nguyen and E. Picco and G. Pourcel and A. Skalli and L. Talandier and B. Vettelschoss and E.A. Vlieg and A. Argyris and P. Bienstman and D. Brunner and J. Dambre and L. Daudet and J.D. Domenech and I. Fischer and F. Horst and S. Massar and C.R. Mirasso and B.J. Offrein and A. Rossi and M.C. Soriano and S. Sygletos and S.K. Turitsyn},
      selected      = {true},
      bibtex_show   = {true},
      preview       = {photonics.png},
}

@InProceedings{AbreuPedersen2024,
  author        = {Steven Abreu and Jens E. Pedersen},
  title         = {Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware},
  year          = {2024},
  booktitle     = {Proceedings of the International Conference of Neuromorphic Systems},
  pdf           = {https://stevenabreu.com/assets/pdf/AbreuPedersen2024.pdf},
  selected      = {true},
  bibtex_show   = {true},
  preview       = {icons2024.png},
}

@InProceedings{AbreuEtAl2023,
  author        = {Steven Abreu and Muhammed Gouda and Alessio Lugnan and Peter Bienstman},
  title         = {Flow Cytometry With Event-Based Vision and Spiking Neuromorphic Hardware},
  year          = {2023},
  selected      = {true},
  booktitle     = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages         = {4138-4146},
  abstract      = {Imaging flow cytometry systems play a critical role in the identification and characterization of large populations of cells or micro-particles. Such systems typically leverage deep artificial neural networks to classify samples. Here we show that an event-based camera and neuromorphic processor can be used in a flow cytometry setup to solve a binary particle classification task with less memory usage, and promising improvements in latency and energy scaling. To reduce the complexity of the spiking neural network, we combine the event-based camera with a free-space optical setup which acts as a non-linear high-dimensional feature map that is computed at the speed of light before the event-based camera receives the signal. We demonstrate, for the first time, a spiking neural network running on neuromorphic hardware for a fully event-based flow cytometry pipeline with 98.45 testing accuracy. Our best artificial neural network on frames of the same data reaches only 97.51, establishing a neuromorphic advantage also in classification accuracy. We further show that our system will scale favorably to more complex classification tasks. We pave the way for real-time classification with throughput of up to 1,000 samples per second and open up new possibilities for online and on-chip learning in flow cytometry applications.},
  html          = {https://openaccess.thecvf.com/content/CVPR2023W/EventVision/html/Abreu_Flow_Cytometry_With_Event-Based_Vision_and_Spiking_Neuromorphic_Hardware_CVPRW_2023_paper.html},
  pdf           = {https://openaccess.thecvf.com/content/CVPR2023W/EventVision/papers/Abreu_Flow_Cytometry_With_Event-Based_Vision_and_Spiking_Neuromorphic_Hardware_CVPRW_2023_paper.pdf},
  bibtex_show   = {true},
  preview       = {dvsflow.gif},
}

@article{CucchiEtAl2022handson,
  title       = {Hands-on reservoir computing: a tutorial for practical implementation},
  author      = {Matteo Cucchi and Steven Abreu and Giuseppe Ciccone and Daniel Brunner and Hans Kleemann},
  year        = {2022},
  journal     = {Neuromorphic Computing and Engineering},
  note        = {Accepted manuscript},
  selected    = {true},
  abstract    = {This manuscript serves a specific purpose: to give readers from fields such as material science, chemistry, or electronics an overview of implementing a reservoir computing (RC) experiment with her/his material system. Introductory literature on the topic is rare and the vast majority of reviews puts forth the basics of RC taking for granted concepts that may be nontrivial to someone unfamiliar with the machine learning field. This is unfortunate considering the large pool of material systems that show nonlinear behavior and short-term memory that may be harnessed to design novel computational paradigms. RC offers a framework for computing with material systems that circumvents typical problems that arise when implementing traditional, fully fledged feedforward neural networks on hardware, such as minimal device-to-device variability and control over each unit/neuron and connection. Instead, one can use a random, untrained reservoir where only the output layer is optimized, for example, with linear regression. In the following, we will highlight the potential of RC for hardware-based neural networks, the advantages over more traditional approaches, and the obstacles to overcome for their implementation. Preparing a high-dimensional nonlinear system as a well-performing reservoir for a specific task is not as easy as it seems at first sight. We hope this tutorial will lower the barrier for scientists attempting to exploit their nonlinear systems for computational tasks typically carried out in the fields of machine learning and artificial intelligence. A simulation tool to accompany this paper is available online.},
  html        = {https://iopscience.iop.org/article/10.1088/2634-4386/ac7db7/meta},
  pdf         = {https://iopscience.iop.org/article/10.1088/2634-4386/ac7db7/pdf},
  bibtex_show = {true},
  preview     = {reservoir.png},
}

@Article{Abreu2019automated,
  author        = {Steven Abreu},
  title         = {Automated architecture design for deep neural networks},
  year          = {2019},
  month         = aug,
  abstract      = {Machine learning has made tremendous progress in recent years and received large amounts of public attention. Though we are still far from designing a full artificially intelligent agent, machine learning has brought us many applications in which computers solve human learning tasks remarkably well. Much of this progress comes from a recent trend within machine learning, called deep learning. Deep learning models are responsible for many state-of-the-art applications of machine learning. Despite their success, deep learning models are hard to train, very difficult to understand, and often times so complex that training is only possible on very large GPU clusters. Lots of work has been done on enabling neural networks to learn efficiently. However, the design and architecture of such neural networks is often done manually through trial and error and expert knowledge. This thesis inspects different approaches, existing and novel, to automate the design of deep feedforward neural networks in an attempt to create less complex models with good performance that take away the burden of deciding on an architecture and make it more efficient to design and train such deep networks.},
  journal       = {ArXiv},
  issue         = {1908.10714},
  archiveprefix = {arXiv},
  eprint        = {1908.10714},
  selected      = {true},
  html          = {https://arxiv.org/abs/1908.10714},
  pdf           = {https://arxiv.org/pdf/1908.10714.pdf},
  bibtex_show   = {true},
  preview       = {jub.png},
}

----------------------
----------------------
----------------------

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,},
  preview={brownian-motion.gif},
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}
