<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>steve abreu</title> <meta name="author" content="steve abreu"/> <meta name="description" content="Academic website and portfolio - Steven Abreu. Based on [*folio](https://github.com/bogoli/-folio). "/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/fav-icon.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://stevenabreu7.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/photo/">photography</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">steve</span> abreu </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg" width="auto" height="auto" alt="prof_pic.jpg"> </picture> </figure> <div class="address"> <p>Bernoulliborg 407</p> <p>9747 AG Groningen</p> <p>The Netherlands</p> <a href="mailto:s.abreu@rug.nl" title="email">s.abreu@rug.nl</a> </div> <div class="social"> <div class="contact-icons"> <a href="https://orcid.org/0000-0002-2272-315X" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=CqbIOvMAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Steven-Abreu/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/stevenabreu7" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/stevenabreu7" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/steveabreu7" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> </div> </div> </div> <div class="clearfix"> <p>I am a PhD student at the AI department of the University of Groningen, working in the <a href="https://www.ai.rug.nl/minds/" target="_blank" rel="noopener noreferrer">MINDS</a> group under the supervision of <a href="https://scholar.google.com/citations?hl=en&amp;user=0uztVbMAAAAJ&amp;view_op=list_works" target="_blank" rel="noopener noreferrer">Prof. Herbert Jaeger</a> and co-supervision of <a href="https://www.rug.nl/research/zernike/bio-inspired-circuits-and-systems/chicca-group/?lang=en" target="_blank" rel="noopener noreferrer">Prof. Elisabetta Chicca</a>. I am part of the <a href="https://www.rug.nl/research/fse/cognitive-systems-and-materials/?lang=en" target="_blank" rel="noopener noreferrer">CogniGron</a> research center for cognitive computing and funded by the European project <a href="http://postdigital.astonphotonics.uk" target="_blank" rel="noopener noreferrer">Post-Digital</a>. I’m currently on leave from my PhD position in Groningen to do research internships at Google and Intel.</p> <p>In research I keep a dual focus on <strong>advancing machine learning</strong> while delving into <strong>novel compute paradigms and hardware for AI</strong>, especially those taking inspiration from the brain. I enjoy cross-disciplinary research between AI, computer science, neuroscience, physics, and cognitive science.</p> <p>Within ML, I work on <strong>efficient machine learning</strong> (enabling AI on low-power hardware) and I am interested in continual learning (e.g. using brain-inspired neuromodulation or plasticity rules), meta-learning, and neurosymbolic programming. To make progress towards well-aligned and interpretable AI, I work on <strong>mechanistic interpretability</strong> and reverse-engineering of ML models.</p> <p>For my PhD I work on <strong>physical and brain-inspired computing</strong>, where I aim to develop theories that align computation with physics, in order to make better use of neuromorphic chips, photonic devices, and other physical computing systems. I aim to develop <strong>computational abstractions in physical substrates</strong> (e.g. through the neuromorphic intermediate representation, <a href="https://github.com/neuromorphs/NIR" target="_blank" rel="noopener noreferrer">NIR</a>), new <strong>hardware-compatible efficient learning algorithms</strong>, and principled ways of <strong><em>programming</em> novel AI hardware</strong> (confronting challenges like device mismatch and limited observability). </p> <p>I am also a hobby photographer, an enthusiastic coffee brewer, an avid motorcyclist, I like to read, travel, and go to music and art events.</p> </div> <div class="news" style="margin-bottom: -20px;"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 2024</th> <td> Spent two weeks at Telluride in the <a href="https://sites.google.com/view/telluride-2024/topic-areas-2024/lt24-language-and-thought" target="_blank" rel="noopener noreferrer">Language and Thought topic</a> area, presented our work on quantized SSMs at <a href="https://icml.cc" target="_blank" rel="noopener noreferrer">ICML</a> in Vienna, and our neuromorphic programming paper at <a href="https://iconsneuromorphic.cc/" target="_blank" rel="noopener noreferrer">ICONS</a> in Virginia! </td> </tr> <tr> <th scope="row">May 2024</th> <td> Starting my research internship at Intel’s Neuromorphic Computing Lab, working on neuromorphic transformer-like architectures based on state space models. </td> </tr> <tr> <th scope="row">Dec 2023</th> <td> Starting my research internship at Google in Waterloo (Canada), working on efficient and adaptive AR user interfaces with multimodal LLMs. </td> </tr> <tr> <th scope="row">Oct 2023</th> <td> Attending <a href="http://nnpc-conference.com" target="_blank" rel="noopener noreferrer">NNPC</a> in Hannover. Presenting a poster on neuromorphic programming and abstractions. </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/qs5.png"></div> <div id="abreu2024qs5" class="col-sm-8"> <div class="title">Q-S5: Towards Quantized State Space Models</div> <div class="author">Steven Abreu*, Jens E. Pedersen*, Kade M. Heckel*, and Alessandro Pierro </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML) 2024 - NGSM workshop</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a target="_blank" href="http://arxiv.org/abs/2406.09477" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://arxiv.org/pdf/2406.09477" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> <a target="_blank" href="https://github.com/stevenabreu7/Q-S5" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>In the quest for next-generation sequence modeling architectures, State Space Models (SSMs) have emerged as a potent alternative to transformers, particularly for their computational efficiency and suitability for dynamical systems. This paper investigates the effect of quantization on the S5 model to understand its impact on model performance and to facilitate its deployment to edge and resource-constrained platforms. Using quantization-aware training (QAT) and post-training quantization (PTQ), we systematically evaluate the quantization sensitivity of SSMs across different tasks like dynamical systems modeling, Sequential MNIST (sMNIST) and most of the Long Range Arena (LRA). We present fully quantized S5 models whose test accuracy drops less than 1% on sMNIST and most of the LRA. We find that performance on most tasks degrades significantly for recurrent weights below 8-bit precision, but that other components can be compressed further without significant loss of performance. Our results further show that PTQ only performs well on language-based LRA tasks whereas all others require QAT. Our investigation provides necessary insights for the continued development of efficient and hardware-optimized SSMs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">abreu2024qs5</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Q-S5: Towards Quantized State Space Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu*, Steven and Pedersen*, Jens E. and Heckel*, Kade M. and Pierro, Alessandro}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2406.09477}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Presented at ICML workshop NGSM}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML) 2024 - NGSM workshop}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/mambaptq.png"></div> <div id="pierro2024mambaptqoutlierchannelsrecurrent" class="col-sm-8"> <div class="title">Mamba-PTQ: Outlier Channels in Recurrent Large Language Models</div> <div class="author">Alessandro Pierro*, and Steven Abreu* </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML) 2024 - ES-FOMO-II workshop</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a target="_blank" href="http://arxiv.org/abs/2407.12397" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://arxiv.org/pdf/2407.12397" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Modern recurrent layers are emerging as a promising path toward edge deployment of foundation models, especially in the context of large language models (LLMs). Compressing the whole input sequence in a finite-dimensional representation enables recurrent layers to model long-range dependencies while maintaining a constant inference cost for each token and a fixed memory requirement. However, the practical deployment of LLMs in resource-limited environments often requires further model compression, such as quantization and pruning. While these techniques are well-established for attention-based models, their effects on recurrent layers remain underexplored. In this preliminary work, we focus on post-training quantization for recurrent LLMs and show that Mamba models exhibit the same pattern of outlier channels observed in attention-based LLMs. We show that the reason for the difficulty of quantizing SSMs is caused by activation outliers, similar to those observed in transformer-based LLMs. We report baseline results for post-training quantization of Mamba that do not take into account the activation outliers and suggest first steps for outlier-aware quantization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pierro2024mambaptqoutlierchannelsrecurrent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mamba-PTQ: Outlier Channels in Recurrent Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pierro*, Alessandro and Abreu*, Steven}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.12397}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Presented at ICML workshop ES-FOMO-II}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML) 2024 - ES-FOMO-II workshop}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/nir.png"></div> <div id="pedersen2023neuromorphicintermediaterepresentationunified" class="col-sm-8"> <div class="title">Neuromorphic Intermediate Representation: A Unified Instruction Set for Interoperable Brain-Inspired Computing</div> <div class="author">Jens E. Pedersen*, Steven Abreu*, Matthias Jobst, Gregor Lenz, Vittorio Fra, Felix C. Bauer, Dylan R. Muir, Peng Zhou, Bernhard Vogginger, Kade Heckel, Gianvito Urgese, Sadasivan Shankar, Terrence C. Stewart, Jason K. Eshraghian, and Sadique Sheik </div> <div class="periodical"> <em>Nature Communications (in press)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a target="_blank" href="http://arxiv.org/abs/2311.14641" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://arxiv.org/pdf/2311.14641" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> <a target="_blank" href="https://github.com/neuromorphs/nir" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Spiking neural networks and neuromorphic hardware platforms that emulate neural dynamics are slowly gaining momentum and entering main-stream usage. Despite a well-established mathematical foundation for neural dynamics, the implementation details vary greatly across different platforms. Correspondingly, there are a plethora of software and hardware implementations with their own unique technology stacks. Consequently, neuromorphic systems typically diverge from the expected computational model, which challenges the reproducibility and reliability across platforms. Additionally, most neuromorphic hardware is limited by its access via a single software frameworks with a limited set of training procedures. Here, we establish a common reference-frame for computations in neuromorphic systems, dubbed the Neuromorphic Intermediate Representation (NIR). NIR defines a set of computational primitives as idealized continuous-time hybrid systems that can be composed into graphs and mapped to and from various neuromorphic technology stacks. By abstracting away assumptions around discretization and hardware constraints, NIR faithfully captures the fundamental computation, while simultaneously exposing the exact differences between the evaluated implementation and the idealized mathematical formalism. We reproduce three NIR graphs across 7 neuromorphic simulators and 4 hardware platforms, demonstrating support for an unprecedented number of neuromorphic systems. With NIR, we decouple the evolution of neuromorphic hardware and software, ultimately increasing the interoperability between platforms and improving accessibility to neuromorphic technologies. We believe that NIR is an important step towards the continued study of brain-inspired hardware and bottom-up approaches aimed at an improved understanding of the computational underpinnings of nervous systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pedersen2023neuromorphicintermediaterepresentationunified</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neuromorphic Intermediate Representation: A Unified Instruction Set for Interoperable Brain-Inspired Computing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pedersen*, Jens E. and Abreu*, Steven and Jobst, Matthias and Lenz, Gregor and Fra, Vittorio and Bauer, Felix C. and Muir, Dylan R. and Zhou, Peng and Vogginger, Bernhard and Heckel, Kade and Urgese, Gianvito and Shankar, Sadasivan and Stewart, Terrence C. and Eshraghian, Jason K. and Sheik, Sadique}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Communications (in press)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/parseego4d.png"></div> <div id="abreu2024parseego4dpersonalactionrecommendation" class="col-sm-8"> <div class="title">PARSE-Ego4D: Personal Action Recommendation Suggestions for Egocentric Videos</div> <div class="author"> <em>Steven Abreu</em>, Tiffany D. Do, Karan Ahuja, Eric J. Gonzalez, Lee Payne, Daniel McDuff, and Mar Gonzalez-Franco </div> <div class="periodical"> <em>under review</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a target="_blank" href="http://arxiv.org/abs/2407.09503" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://arxiv.org/pdf/2407.09503" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> <a target="_blank" href="https://github.com/parse-ego4d/parse-ego4d.github.io" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">Code</a> <a target="_blank" href="https://parse-ego4d.github.io/" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">Website</a> </div> <div class="abstract hidden"> <p>Intelligent assistance involves not only understanding but also action. Existing ego-centric video datasets contain rich annotations of the videos, but not of actions that an intelligent assistant could perform in the moment. To address this gap, we release PARSE-Ego4D, a new set of personal action recommendation annotations for the Ego4D dataset. We take a multi-stage approach to generating and evaluating these annotations. First, we used a prompt-engineered large language model (LLM) to generate context-aware action suggestions and identified over 18,000 action suggestions. While these synthetic action suggestions are valuable, the inherent limitations of LLMs necessitate human evaluation. To ensure high-quality and user-centered recommendations, we conducted a large-scale human annotation study that provides grounding in human preferences for all of PARSE-Ego4D. We analyze the inter-rater agreement and evaluate subjective preferences of participants. Based on our synthetic dataset and complete human annotations, we propose several new tasks for action suggestions based on ego-centric videos. We encourage novel solutions that improve latency and energy requirements. The annotations in PARSE-Ego4D will support researchers and developers who are working on building action recommendation systems for augmented and virtual reality systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">abreu2024parseego4dpersonalactionrecommendation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PARSE-Ego4D: Personal Action Recommendation Suggestions for Egocentric Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu, Steven and Do, Tiffany D. and Ahuja, Karan and Gonzalez, Eric J. and Payne, Lee and McDuff, Daniel and Gonzalez-Franco, Mar}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.09503}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{under review}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/photonics.png"></div> <div id="abreu2024photonics" class="col-sm-8"> <div class="title">A photonics perspective on computing with physical substrates</div> <div class="author">S. Abreu, I. Boikov, M. Goldmann, T. Jonuzi, A. Lupo, S. Masaad, L. Nguyen, E. Picco, G. Pourcel, A. Skalli, L. Talandier, B. Vettelschoss, E.A. Vlieg, A. Argyris, P. Bienstman, D. Brunner, J. Dambre, L. Daudet, J.D. Domenech, I. Fischer, F. Horst, S. Massar, C.R. Mirasso, B.J. Offrein, A. Rossi, M.C. Soriano, S. Sygletos, and S.K. Turitsyn </div> <div class="periodical"> <em>Reviews in Physics</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2405428324000030" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>We provide a perspective on the fundamental relationship between physics and computation, exploring the conditions under which a physical system can be harnessed for computation and the practical means to achieve this. Unlike traditional digital computers that impose discreteness on continuous substrates, unconventional computing embraces the inherent properties of physical systems. Exploring simultaneously the intricacies of physical implementations and applied computational paradigms, we discuss the interdisciplinary developments of unconventional computing. Here, we focus on the potential of photonic substrates for unconventional computing, implementing artificial neural networks to solve data-driven machine learning tasks. Several photonic neural network implementations are discussed, highlighting their potential advantages over electronic counterparts in terms of speed and energy efficiency. Finally, we address the challenges of achieving learning and programmability within physical substrates, outlining key strategies for future research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">abreu2024photonics</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A photonics perspective on computing with physical substrates}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Reviews in Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100093}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2405-4283}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.revip.2024.100093}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu, S. and Boikov, I. and Goldmann, M. and Jonuzi, T. and Lupo, A. and Masaad, S. and Nguyen, L. and Picco, E. and Pourcel, G. and Skalli, A. and Talandier, L. and Vettelschoss, B. and Vlieg, E.A. and Argyris, A. and Bienstman, P. and Brunner, D. and Dambre, J. and Daudet, L. and Domenech, J.D. and Fischer, I. and Horst, F. and Massar, S. and Mirasso, C.R. and Offrein, B.J. and Rossi, A. and Soriano, M.C. and Sygletos, S. and Turitsyn, S.K.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/icons2024.png"></div> <div id="AbreuPedersen2024" class="col-sm-8"> <div class="title">Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware</div> <div class="author"> <em>Steven Abreu</em>, and Jens E. Pedersen </div> <div class="periodical"> <em>In Proceedings of the International Conference of Neuromorphic Systems</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://stevenabreu.com/assets/pdf/AbreuPedersen2024.pdf" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The value of brain-inspired neuromorphic computers critically depends on our ability to program them for relevant tasks. Currently, neuromorphic hardware often relies on machine learning methods adapted from deep learning. However, neuromorphic computers have potential far beyond deep learning if we can only harness their energy efficiency and full computational power. Neuromorphic programming will necessarily be different from conventional programming, requiring a paradigm shift in how we think about programming. This paper presents a conceptual analysis of programming within the context of neuromorphic computing, challenging conventional paradigms and proposing a framework that aligns more closely with the physical intricacies of these systems. Our analysis revolves around five characteristics that are fundamental to neuromorphic programming and provides a basis for comparison to contemporary programming methods and languages. By studying past approaches, we contribute a framework that advocates for underutilized techniques and calls for richer abstractions to effectively instrument the new hardware class.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AbreuPedersen2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu, Steven and Pedersen, Jens E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the International Conference of Neuromorphic Systems}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/dvsflow.gif"></div> <div id="AbreuEtAl2023" class="col-sm-8"> <div class="title">Flow Cytometry With Event-Based Vision and Spiking Neuromorphic Hardware</div> <div class="author"> <em>Steven Abreu</em>, Muhammed Gouda, Alessio Lugnan, and Peter Bienstman </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2023W/EventVision/html/Abreu_Flow_Cytometry_With_Event-Based_Vision_and_Spiking_Neuromorphic_Hardware_CVPRW_2023_paper.html" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">HTML</a> <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2023W/EventVision/papers/Abreu_Flow_Cytometry_With_Event-Based_Vision_and_Spiking_Neuromorphic_Hardware_CVPRW_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Imaging flow cytometry systems play a critical role in the identification and characterization of large populations of cells or micro-particles. Such systems typically leverage deep artificial neural networks to classify samples. Here we show that an event-based camera and neuromorphic processor can be used in a flow cytometry setup to solve a binary particle classification task with less memory usage, and promising improvements in latency and energy scaling. To reduce the complexity of the spiking neural network, we combine the event-based camera with a free-space optical setup which acts as a non-linear high-dimensional feature map that is computed at the speed of light before the event-based camera receives the signal. We demonstrate, for the first time, a spiking neural network running on neuromorphic hardware for a fully event-based flow cytometry pipeline with 98.45 testing accuracy. Our best artificial neural network on frames of the same data reaches only 97.51, establishing a neuromorphic advantage also in classification accuracy. We further show that our system will scale favorably to more complex classification tasks. We pave the way for real-time classification with throughput of up to 1,000 samples per second and open up new possibilities for online and on-chip learning in flow cytometry applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AbreuEtAl2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu, Steven and Gouda, Muhammed and Lugnan, Alessio and Bienstman, Peter}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Flow Cytometry With Event-Based Vision and Spiking Neuromorphic Hardware}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4138-4146}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/reservoir.png"></div> <div id="CucchiEtAl2022handson" class="col-sm-8"> <div class="title">Hands-on reservoir computing: a tutorial for practical implementation</div> <div class="author">Matteo Cucchi*, Steven Abreu*, Giuseppe Ciccone, Daniel Brunner, and Hans Kleemann </div> <div class="periodical"> <em>Neuromorphic Computing and Engineering</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://iopscience.iop.org/article/10.1088/2634-4386/ac7db7/meta" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">HTML</a> <a target="_blank" href="https://iopscience.iop.org/article/10.1088/2634-4386/ac7db7/pdf" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>This manuscript serves a specific purpose: to give readers from fields such as material science, chemistry, or electronics an overview of implementing a reservoir computing (RC) experiment with her/his material system. Introductory literature on the topic is rare and the vast majority of reviews puts forth the basics of RC taking for granted concepts that may be nontrivial to someone unfamiliar with the machine learning field. This is unfortunate considering the large pool of material systems that show nonlinear behavior and short-term memory that may be harnessed to design novel computational paradigms. RC offers a framework for computing with material systems that circumvents typical problems that arise when implementing traditional, fully fledged feedforward neural networks on hardware, such as minimal device-to-device variability and control over each unit/neuron and connection. Instead, one can use a random, untrained reservoir where only the output layer is optimized, for example, with linear regression. In the following, we will highlight the potential of RC for hardware-based neural networks, the advantages over more traditional approaches, and the obstacles to overcome for their implementation. Preparing a high-dimensional nonlinear system as a well-performing reservoir for a specific task is not as easy as it seems at first sight. We hope this tutorial will lower the barrier for scientists attempting to exploit their nonlinear systems for computational tasks typically carried out in the fields of machine learning and artificial intelligence. A simulation tool to accompany this paper is available online.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CucchiEtAl2022handson</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hands-on reservoir computing: a tutorial for practical implementation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cucchi*, Matteo and Abreu*, Steven and Ciccone, Giuseppe and Brunner, Daniel and Kleemann, Hans}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neuromorphic Computing and Engineering}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Accepted manuscript}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/jub.png"></div> <div id="Abreu2019automated" class="col-sm-8"> <div class="title">Automated architecture design for deep neural networks</div> <div class="author"> <em>Steven Abreu</em> </div> <div class="periodical"> <em>ArXiv</em> Aug 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a target="_blank" href="http://arxiv.org/abs/1908.10714" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a target="_blank" href="https://arxiv.org/abs/1908.10714" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">HTML</a> <a target="_blank" href="https://arxiv.org/pdf/1908.10714.pdf" class="btn btn-sm z-depth-0" role="button" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Machine learning has made tremendous progress in recent years and received large amounts of public attention. Though we are still far from designing a full artificially intelligent agent, machine learning has brought us many applications in which computers solve human learning tasks remarkably well. Much of this progress comes from a recent trend within machine learning, called deep learning. Deep learning models are responsible for many state-of-the-art applications of machine learning. Despite their success, deep learning models are hard to train, very difficult to understand, and often times so complex that training is only possible on very large GPU clusters. Lots of work has been done on enabling neural networks to learn efficiently. However, the design and architecture of such neural networks is often done manually through trial and error and expert knowledge. This thesis inspects different approaches, existing and novel, to automate the design of deep feedforward neural networks in an attempt to create less complex models with good performance that take away the burden of deciding on an architecture and make it more efficient to design and train such deep networks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Abreu2019automated</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abreu, Steven}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated architecture design for deep neural networks}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ArXiv}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{1908.10714}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1908.10714}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>